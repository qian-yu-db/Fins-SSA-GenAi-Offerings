{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d56102d1-b53a-4ee7-ae22-4dcfde4c2b56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Purpose\n",
    "\n",
    "* Setup Whisper v3 Large PT Endpoint\n",
    "  * Whisper v3 already exists in `system.ai.whisper_large_v3`\n",
    "* Perform Audio Transcription using AI Function for LLM Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6306a256-9f8d-4473-bc90-ab2dbeb47871",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet databricks-sdk==0.28.0 mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6727516c-dca9-472a-aee1-731d0ec81886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74789ac5-ff7a-41a2-bd17-561d9baf9b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"endpoint_name\", defaultValue=\"whisper_large_v3_fins_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75aaecf4-5352-42c1-ad26-17ddbe0e81f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "version = \"1\"\n",
    "model_uc_path = \"system.ai.whisper_large_v3\"\n",
    "endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
    "\n",
    "\n",
    "print(f\"Unity Catalog Model Path: {model_uc_path}\")\n",
    "print(f\"Endpoint Name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b930119c-a92b-4f34-9aca-d8f11c13c1a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy the Whisper Large V3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f88c9f3-7269-4215-b886-b7e6bee1cf68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput\n",
    "from databricks.sdk.service.serving import AutoCaptureConfigInput\n",
    "\n",
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "138ca186-fcd0-4463-af09-c3e077c687dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workload_type = \"GPU_LARGE\"\n",
    "version = '3' # latest version based on system.ai\n",
    "\n",
    "config = EndpointCoreConfigInput.from_dict({\n",
    "    \"served_models\": [\n",
    "        {\n",
    "            \"name\": endpoint_name,\n",
    "            \"model_name\": model_uc_path,\n",
    "            \"model_version\": version,\n",
    "            \"workload_type\": workload_type,\n",
    "            \"workload_size\": \"Small\",\n",
    "            \"scale_to_zero_enabled\": \"True\",\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "model_details = w.serving_endpoints.create_and_wait(name=endpoint_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c65c72a2-b149-4362-93b2-2eb30a38ebf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Audio Transcription with AI Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c366a765-2c62-403f-859b-2b7e7166887c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Ingestion Raw Audio with autoloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171208bf-673e-4ad7-b68b-e76036f4380d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "volume_checkpoints = f\"/Volumes/{catalog}/{schema}/checkpoints\"\n",
    "volume_path = f\"/Volumes/{catalog}/{schema}/volume_audio_files/\"\n",
    "\n",
    "spark.sql(f\"USE CATALOG {catalog};\")\n",
    "spark.sql(f\"USE SCHEMA {schema};\")\n",
    "\n",
    "df = (spark.readStream.format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"binaryFile\")\n",
    "    .option(\"recursiveFileLookup\", \"true\")\n",
    "    .load(volume_path))\n",
    "\n",
    "(df.writeStream\n",
    " .trigger(availableNow=True)\n",
    " .option(\"checkpointLocation\", f'{volume_checkpoints}/raw_audio')\n",
    " .table('raw_audio').awaitTermination()\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed5cf99-591f-42f1-ad7f-ee2a22899ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ai_query_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {catalog}.{schema}.audio_transcription AS ( \n",
    "  select\n",
    "    regexp_extract(path, r'.*\\/policy_no_(\\d+)\\/.*', 1) AS policy_number,\n",
    "    ai_query(\n",
    "      '{endpoint_name}',\n",
    "      content,\n",
    "      failOnError => True\n",
    "    ) as transcripts\n",
    "  from {catalog}.{schema}.raw_audio\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(ai_query_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6c698b2-c5dc-4ea8-a19f-a231e8082c88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(f\"audio_transcription\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-Audio-Transcription-with-AI-Query",
   "widgets": {
    "endpoint_name": {
     "currentValue": "whisper_large_v3_fins_genai",
     "nuid": "5672f03d-e792-4141-bced-ba5ff0f925cb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "whisper_large_v3_fins_genai",
      "label": null,
      "name": "endpoint_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "whisper_large_v3_fins_genai",
      "label": null,
      "name": "endpoint_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
